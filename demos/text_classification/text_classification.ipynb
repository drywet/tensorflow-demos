{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z74u4hgv1iSv",
        "outputId": "143f591e-c070-40be-c3d2-c87ef0f91e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.14.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from shutil import copyfileobj\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "from urllib.request import urlopen\n",
        "import string\n",
        "import re\n",
        "\n",
        "print(f\"TF version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def archive(dir: Path):\n",
        "#     with zipfile.ZipFile(f\"{dir}.zip\", \"w\", zipfile.ZIP_STORED) as zip_file:\n",
        "#         for entry in dir.rglob(\"*\"):\n",
        "#             zip_file.write(entry, entry.relative_to(dir))\n",
        "#\n",
        "#\n",
        "# def unarchive(file: Path):\n",
        "#     with zipfile.ZipFile(file, \"r\") as zip_file:\n",
        "#         zip_file.extractall(file.with_suffix(\"\"))"
      ],
      "metadata": {
        "id": "Dg8alFFC1nVj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, dataset_file_path):\n",
        "    path = Path(dataset_file_path)\n",
        "    os.makedirs(path.parent, exist_ok=True)\n",
        "    if not path.exists():\n",
        "        print(f\"Downloading {path}\")\n",
        "        with urlopen(url) as fsrc, open(path, \"wb\") as fdst:\n",
        "            copyfileobj(fsrc, fdst)\n",
        "    else:\n",
        "        print(f\"File {path} exists\")"
      ],
      "metadata": {
        "id": "JEXGp0CC1oBa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIE07sJG1ooA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"tmp/text_classification.csv\"\n",
        "batch_size = 2048\n",
        "seed = 123\n",
        "max_seq_length = 100\n",
        "vocab_size = 20000"
      ],
      "metadata": {
        "id": "RJtd6MR31qRD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_file(\"https://raw.githubusercontent.com/sealuzh/user_quality/master/csv_files/reviews.csv\", dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "274TY6py1qfQ",
        "outputId": "d11e3570-00af-4836-8301-b98e2fda16b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File tmp/text_classification.csv exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.experimental.make_csv_dataset(\n",
        "    dataset_path,\n",
        "    batch_size=batch_size,\n",
        "    # column_names=None,\n",
        "    # column_defaults=None,\n",
        "    label_name=None,\n",
        "    select_columns=[\"review\", \"star\"],\n",
        "    # field_delim=\",\",\n",
        "    # use_quote_delim=True,\n",
        "    # na_value=\"\",\n",
        "    # header=True,\n",
        "    num_epochs=1,\n",
        "    shuffle=True,\n",
        "    shuffle_buffer_size=10000,\n",
        "    shuffle_seed=seed,\n",
        "    # prefetch_buffer_size=None,\n",
        "    # num_parallel_reads=None,\n",
        "    # sloppy=False,\n",
        "    # num_rows_for_inference=100,\n",
        "    # compression_type=None,\n",
        "    # ignore_errors=False,\n",
        "    # encoding=\"utf-8\"\n",
        ").map(lambda x: (x[\"review\"], float(x[\"star\"])))"
      ],
      "metadata": {
        "id": "F1H3HQ2X1raS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iAi0Buz1sDR",
        "outputId": "92d42eac-84e1-4977-f9dd-51d0c0cf92d7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([b'Fine', b'Good',\n",
              "        b'Keeps Crashing i have the bios flash and startup and game keeps crashing',\n",
              "        ...,\n",
              "        b\"like it but I'm trying to work the BIOS and make Dreamcast games work. Give me some help with this.\",\n",
              "        b\"Good but the mic emulation no work good enough on nexus 5 seaman can rarely understand me an usually thinks I'm yelling at him\",\n",
              "        b'Nice Patelnavin'], dtype=object),\n",
              " array([5., 5., 1., ..., 4., 4., 5.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = list(dataset.unbatch())"
      ],
      "metadata": {
        "id": "tdJygcqb1tVQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_size = 0.9\n",
        "train_dataset = dataset[:int(len(dataset) * split_size)]\n",
        "validation_dataset = dataset[len(train_dataset):]\n",
        "print(len(train_dataset), len(validation_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iSOfINL1vBo",
        "outputId": "b50dd76e-b14a-4083-d1a7-4eaa2da9396b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "259258 28807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llILD2Vg1v9C"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TextVectorization layer is not supported by h5 model format"
      ],
      "metadata": {
        "id": "7t4tyxot1w12"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [review.numpy().decode(\"utf-8\") for review, rating in dataset]"
      ],
      "metadata": {
        "id": "Qp8xv-E91xlx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(reviews)"
      ],
      "metadata": {
        "id": "pWwsW_S61yJn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window(lst, width, step):\n",
        "    assert width > 0\n",
        "    assert step > 0\n",
        "    windows = []\n",
        "    i = 0\n",
        "    windows.append(lst[:width])\n",
        "    i += step\n",
        "    while i + width <= len(lst):\n",
        "        windows.append(lst[i:i + width])\n",
        "        i += step\n",
        "    return windows"
      ],
      "metadata": {
        "id": "dtG2DLE5yWYK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences_with_ratings(dataset):\n",
        "    reviews = [review.numpy().decode(\"utf-8\") for review, rating in dataset]\n",
        "    ratings = [rating for review, rating in dataset]\n",
        "    sequences = tokenizer.texts_to_sequences(reviews)\n",
        "    sequences2 = [(window, rating) for sequence, rating in zip(sequences, ratings)\n",
        "                  for window in sliding_window(sequence, max_seq_length, 10)]\n",
        "    # padding=post is required for cuDNN LSTM implementation\n",
        "    padded = tf.keras.utils.pad_sequences(\n",
        "        [x[0] for x in sequences2],\n",
        "        maxlen=max_seq_length,\n",
        "        padding=\"post\",\n",
        "        truncating=\"post\",\n",
        "    )\n",
        "    return reviews, padded, [x[1] for x in sequences2]\n",
        "\n",
        "\n",
        "train_reviews, train_reviews_padded, train_ratings = texts_to_sequences_with_ratings(train_dataset)\n",
        "validation_reviews, validation_reviews_padded, validation_ratings = texts_to_sequences_with_ratings(validation_dataset)"
      ],
      "metadata": {
        "id": "WrL8ctMD1yt4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_reviews_padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMoh-Ri-y6T8",
        "outputId": "6a9f3bad-249a-412d-9e4c-8b93fd4fb6e7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "261788"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = tokenizer.num_words\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AUwRzAy1zVQ",
        "outputId": "cab62492-3480-46fc-9ee0-022f09b976a7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plus OOV token and 0 index representing a mask\n",
        "input_dim = vocab_size + 2"
      ],
      "metadata": {
        "id": "93QKsmvm10EZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h94bcMEN13GA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # text_vectorization_layer,\n",
        "\n",
        "    layers.Embedding(input_dim, 16, mask_zero=True, input_length=max_seq_length),\n",
        "    layers.Bidirectional(layers.LSTM(32)),\n",
        "    # tf.keras.layers.Flatten(),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1),\n",
        "    # layers.Dense(class_count, activation=\"softmax\", name=f\"output\")\n",
        "])"
      ],
      "metadata": {
        "id": "UOHhYolB106p"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlCt7dDK12ho",
        "outputId": "49ad1cba-7bf6-407b-ba03-1e78b420d32e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 16)           320032    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 64)                12544     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 333633 (1.27 MB)\n",
            "Trainable params: 333633 (1.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\"mae\"]\n",
        ")"
      ],
      "metadata": {
        "id": "vrqeM4dU14uo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath=f\"tmp/checkpoints\",\n",
        "#     save_weights_only=False,\n",
        "#     monitor=f\"val_acc\",\n",
        "#     mode=\"max\",\n",
        "#     save_best_only=True,\n",
        "# )\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=f\"val_loss\",\n",
        "    mode=\"max\",\n",
        ")"
      ],
      "metadata": {
        "id": "w5GsRjcW15wh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    x=np.array(train_reviews_padded),\n",
        "    y=np.array(train_ratings),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[reduce_lr_callback],\n",
        "    validation_data=(np.array(validation_reviews_padded), np.array(validation_ratings)),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO54wFXR16np",
        "outputId": "74c0afe5-eeb3-4db8-83c0-80fd5d3111d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "128/128 [==============================] - 10s 79ms/step - loss: 1.1146 - mae: 0.7770 - val_loss: 1.2268 - val_mae: 0.8211 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "128/128 [==============================] - 9s 68ms/step - loss: 1.0590 - mae: 0.7519 - val_loss: 1.1893 - val_mae: 0.8076 - lr: 0.0010\n",
            "Epoch 3/10\n",
            " 23/128 [====>.........................] - ETA: 6s - loss: 1.0179 - mae: 0.7339"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(validation_reviews[:10], model(validation_reviews_padded[:10]), validation_ratings[:10]))"
      ],
      "metadata": {
        "id": "87_ZuL8A17YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history[\"mae\"]\n",
        "val_acc = history.history[\"val_mae\"]\n",
        "\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs_range, acc, label=\"Training MAE\")\n",
        "plt.plot(epochs_range, val_acc, label=\"Validation MAE\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.title(\"Training and Validation MAE\")\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
        "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u3tDiG2M2NkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"tmp/model.h5\", save_format=\"h5\")"
      ],
      "metadata": {
        "id": "Grcr1XmZ4keh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P5ugysAJS4H9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}