{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "COLAB = \"google.colab\" in sys.modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsALsQzKxy4q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "95ac3267-133c-4c7b-d5d2-868190cf2a4e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfileobj\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "\n",
    "print(f\"TF version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def archive(dir: Path):\n",
    "    with zipfile.ZipFile(f\"{dir}.zip\", \"w\", zipfile.ZIP_STORED) as zip_file:\n",
    "        for entry in dir.rglob(\"*\"):\n",
    "            zip_file.write(entry, entry.relative_to(dir))\n",
    "\n",
    "\n",
    "def unarchive(file: Path):\n",
    "    with zipfile.ZipFile(file, \"r\") as zip_file:\n",
    "        zip_file.extractall(file.with_suffix(\"\"))"
   ],
   "metadata": {
    "id": "KnmeqkUhyAkT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def download_file(url, dataset_file_path):\n",
    "    path = Path(dataset_file_path)\n",
    "    os.makedirs(path.parent, exist_ok=True)\n",
    "    if not path.exists():\n",
    "        print(f\"Downloading {path}\")\n",
    "        with urlopen(url) as fsrc, open(path, \"wb\") as fdst:\n",
    "            copyfileobj(fsrc, fdst)\n",
    "    else:\n",
    "        print(f\"File {path} exists\")"
   ],
   "metadata": {
    "id": "hhuP0xfPyG-x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "JQcemijSyJ4n"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tmp_path = \"tmp/image_classification\"\n",
    "dataset_path = f\"{tmp_path}/dataset\"\n",
    "batch_size = 32\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "image_size = (image_width, image_height)\n",
    "image_size_3 = image_size + (3,)\n",
    "seed = 123\n",
    "class_count = 20"
   ],
   "metadata": {
    "id": "soeI4svCyMfM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "download_file(\"https://huggingface.co/datasets/Matthijs/snacks/resolve/main/images.zip\", f\"{dataset_path}.zip\")"
   ],
   "metadata": {
    "id": "rai5Gq0MyMwK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2855a1fd-0f6d-40a1-bc1d-16089d16bd87"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "unarchive(Path(f\"tmp/image_classification/dataset.zip\"))"
   ],
   "metadata": {
    "id": "_yOTjAUNyOFC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f\"{dataset_path}/data/train\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    interpolation=\"bicubic\",\n",
    ")\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=f\"{dataset_path}/data/val\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    shuffle=False,\n",
    "    seed=seed,\n",
    "    interpolation=\"bicubic\",\n",
    ")\n",
    "assert train_dataset.class_names == validation_dataset.class_names\n",
    "assert len(train_dataset.class_names) == class_count\n",
    "train_dataset=train_dataset.cache().prefetch(10000).shuffle(10000)\n",
    "validation_dataset=validation_dataset.cache().prefetch(10000)"
   ],
   "metadata": {
    "id": "8T5ooNpAyPLh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9f4f8f69-b643-49ff-dcce-f007d0fcbf75"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Input(image_size_3),\n",
    "\n",
    "#     tf.keras.layers.RandomFlip(mode=\"horizontal\"),\n",
    "#     tf.keras.layers.RandomRotation(0.05),\n",
    "#     tf.keras.layers.RandomZoom(0.15),\n",
    "#     tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "#     tf.keras.layers.RandomContrast(0.15),\n",
    "#     tf.keras.layers.RandomBrightness(0.1, value_range=[0.0, 255.0]),\n",
    "#     tf.keras.layers.Layer(name=\"augmentation_end\"),\n",
    "\n",
    "#     tf.keras.layers.Rescaling(1 / 255.0),\n",
    "\n",
    "#     # Pixel noise\n",
    "#     tf.keras.layers.Dropout(0.1, noise_shape=image_size + (1,), name=f\"dropout_xy_1\"),\n",
    "#     # Horizontal line noise\n",
    "#     tf.keras.layers.Dropout(0.05, noise_shape=(image_height, 1, 1), name=f\"dropout_x_1\"),\n",
    "#     # Vertical line noise\n",
    "#     tf.keras.layers.Dropout(0.05, noise_shape=(1, image_width, 1), name=f\"dropout_y_1\"),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(32, (3, 3), activation=\"gelu\", name=f\"conv2d_1\"),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_1\"),\n",
    "#     tf.keras.layers.Dropout(0.05, name=f\"dropout_1\"),\n",
    "#     tf.keras.layers.BatchNormalization(name=f\"batch_norm_1\"),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(64, (3, 3), activation=\"gelu\", name=f\"conv2d_2\"),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_2\"),\n",
    "#     tf.keras.layers.Dropout(0.05, name=f\"dropout_2\"),\n",
    "#     tf.keras.layers.BatchNormalization(name=f\"batch_norm_2\"),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(64, (3, 3), activation=\"gelu\", name=f\"conv2d_3\"),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_3\"),\n",
    "#     tf.keras.layers.Dropout(0.05, name=f\"dropout_3\"),\n",
    "#     tf.keras.layers.BatchNormalization(name=f\"batch_norm_3\"),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(128, (3, 3), activation=\"gelu\", name=f\"conv2d_4\"),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_4\"),\n",
    "#     tf.keras.layers.Dropout(0.05, name=f\"dropout_4\"),\n",
    "#     tf.keras.layers.BatchNormalization(name=f\"batch_norm_4\"),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(128, (3, 3), activation=\"gelu\", name=f\"conv2d_5\"),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_5\"),\n",
    "#     tf.keras.layers.Dropout(0.05, name=f\"dropout_5\"),\n",
    "#     tf.keras.layers.BatchNormalization(name=f\"batch_norm_5\"),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(256, (3, 3), activation=\"gelu\", name=f\"conv2d_6\"),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_6\"),\n",
    "#     tf.keras.layers.Dropout(0.05, name=f\"dropout_6\"),\n",
    "#     tf.keras.layers.BatchNormalization(name=f\"batch_norm_6\"),\n",
    "\n",
    "#     tf.keras.layers.Flatten(name=f\"flatten\"),\n",
    "#     tf.keras.layers.Dropout(0.1, name=f\"dropout_7\"),\n",
    "#     tf.keras.layers.Dense(64, activation=\"gelu\", name=f\"dense_1\"),\n",
    "#     tf.keras.layers.Dense(class_count, activation=\"softmax\", name=f\"output\"),\n",
    "# ])"
   ],
   "metadata": {
    "id": "ZHwyHXHIyQZh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model():\n",
    "    input = tf.keras.layers.Input(image_size_3)\n",
    "    layer = input\n",
    "\n",
    "    layer = tf.keras.layers.RandomFlip(mode=\"horizontal\")(layer)\n",
    "    layer = tf.keras.layers.RandomRotation(0.05)(layer)\n",
    "    layer = tf.keras.layers.RandomZoom(0.15)(layer)\n",
    "    layer = tf.keras.layers.RandomTranslation(0.1, 0.1)(layer)\n",
    "    layer = tf.keras.layers.RandomContrast(0.15)(layer)\n",
    "    layer = tf.keras.layers.RandomBrightness(0.1, value_range=[0.0, 255.0])(layer)\n",
    "    layer = tf.keras.layers.Layer(name=\"augmentation_end\")(layer)\n",
    "\n",
    "    layer = tf.keras.layers.Rescaling(1 / 255.0)(layer)\n",
    "\n",
    "    # # Pixel noise\n",
    "    # layer = tf.keras.layers.Dropout(0.1, noise_shape=image_size + (1,), name=f\"dropout_xy_1\")(layer)\n",
    "    # # Horizontal line noise\n",
    "    # layer = tf.keras.layers.Dropout(0.1, noise_shape=(image_height, 1, 1), name=f\"dropout_x_1\")(layer)\n",
    "    # # Vertical line noise\n",
    "    # layer = tf.keras.layers.Dropout(0.1, noise_shape=(1, image_width, 1), name=f\"dropout_y_1\")(layer)\n",
    "\n",
    "    layer = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=f\"conv2d_1\")(layer)\n",
    "    layer = tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_1\")(layer)\n",
    "    # layer = tf.keras.layers.Dropout(0.1, name=f\"dropout_1\")(layer)\n",
    "    # layer = tf.keras.layers.BatchNormalization(name=f\"batch_norm_1\")(layer)\n",
    "    # previous_block = layer\n",
    "\n",
    "    layer = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=f\"conv2d_2\")(layer)\n",
    "    layer = tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_2\")(layer)\n",
    "    # layer = tf.keras.layers.Dropout(0.1, name=f\"dropout_2\")(layer)\n",
    "    # layer = tf.keras.layers.BatchNormalization(name=f\"batch_norm_2\")(layer)\n",
    "    # layer = tf.keras.layers.Add()([layer, tf.keras.layers.AveragePooling2D((2, 2))(previous_block)])\n",
    "    # previous_block = layer\n",
    "\n",
    "    layer = tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=f\"conv2d_3\")(layer)\n",
    "    layer = tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_3\")(layer)\n",
    "    layer = tf.keras.layers.Dropout(0.1, name=f\"dropout_3\")(layer)\n",
    "    # layer = tf.keras.layers.BatchNormalization(name=f\"batch_norm_3\")(layer)\n",
    "    # previous_block = tf.keras.layers.AveragePooling2D((2, 2))(previous_block)\n",
    "    # previous_block = tf.repeat(previous_block, repeats=2, axis=-1)\n",
    "    # # layer = tf.keras.layers.Add()([layer, previous_block])\n",
    "    # previous_block = layer\n",
    "\n",
    "    layer = tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=f\"conv2d_4\")(layer)\n",
    "    layer = tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_4\")(layer)\n",
    "    layer = tf.keras.layers.Dropout(0.05, name=f\"dropout_4\")(layer)\n",
    "    # layer = tf.keras.layers.BatchNormalization(name=f\"batch_norm_4\")(layer)\n",
    "    # layer = tf.keras.layers.Add()([layer, tf.keras.layers.AveragePooling2D((2, 2))(previous_block)])\n",
    "    # previous_block = layer\n",
    "\n",
    "    # layer = tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"gelu\", name=f\"conv2d_5\")(layer)\n",
    "    # layer = tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_5\")(layer)\n",
    "    # layer = tf.keras.layers.Dropout(0.15, name=f\"dropout_5\")(layer)\n",
    "    # layer = tf.keras.layers.BatchNormalization(name=f\"batch_norm_5\")(layer)\n",
    "    # previous_block = tf.keras.layers.AveragePooling2D((2, 2))(previous_block)\n",
    "    # previous_block = tf.repeat(previous_block, repeats=2, axis=-1)\n",
    "    # # layer = tf.keras.layers.Add()([layer, previous_block])\n",
    "    # previous_block = layer\n",
    "\n",
    "    # layer = tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"gelu\", name=f\"conv2d_6\")(layer)\n",
    "    # layer = tf.keras.layers.MaxPooling2D((2, 2), name=f\"maxpooling2d_6\")(layer)\n",
    "    # layer = tf.keras.layers.Dropout(0.15, name=f\"dropout_6\")(layer)\n",
    "    # layer = tf.keras.layers.BatchNormalization(name=f\"batch_norm_6\")(layer)\n",
    "    # # layer = tf.keras.layers.Add()([layer, tf.keras.layers.AveragePooling2D((2, 2))(previous_block)])\n",
    "    # previous_block = layer\n",
    "\n",
    "    layer = tf.keras.layers.Flatten(name=f\"flatten\")(layer)\n",
    "    layer = tf.keras.layers.Dropout(0.15, name=f\"dropout_7\")(layer)\n",
    "    layer = tf.keras.layers.Dense(256, activation=\"relu\", name=f\"dense_1\")(layer)\n",
    "    layer = tf.keras.layers.Dense(class_count, activation=\"softmax\", name=f\"output\")(layer)\n",
    "\n",
    "    return tf.keras.Model(inputs=input, outputs=layer)\n",
    "\n",
    "\n",
    "model = create_model()"
   ],
   "metadata": {
    "id": "Bbt93bcMkDOA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(image_size_3),\n",
    "\n",
    "  tf.keras.layers.RandomFlip(mode=\"horizontal\"),\n",
    "  tf.keras.layers.RandomRotation(0.05),\n",
    "  tf.keras.layers.RandomZoom(0.15),\n",
    "  tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "  tf.keras.layers.RandomContrast(0.15),\n",
    "  tf.keras.layers.RandomBrightness(0.1, value_range=[0.0, 255.0]),\n",
    "  tf.keras.layers.Layer(name=\"augmentation_end\"),\n",
    "\n",
    "  tf.keras.layers.Rescaling(1 / 255.0),\n",
    "\n",
    "  # Pixel noise\n",
    "  # layers.Dropout(0.05, noise_shape=image_size + (1,), name=f\"dropout_xy_1\"),\n",
    "  # # Horizontal line noise\n",
    "  # layers.Dropout(0.1, noise_shape=(image_height, 1, 1), name=f\"dropout_x_1\"),\n",
    "  # # Vertical line noise\n",
    "  # layers.Dropout(0.1, noise_shape=(1, image_width, 1), name=f\"dropout_y_1\"),\n",
    "\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  # layers.Dropout(0.05),\n",
    "  # layers.LayerNormalization(),\n",
    "  # layers.BatchNormalization(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  # layers.Dropout(0.05),\n",
    "  # layers.LayerNormalization(),\n",
    "  # layers.BatchNormalization(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  # layers.Dropout(0.05),\n",
    "  # layers.LayerNormalization(),\n",
    "  # layers.BatchNormalization(),\n",
    "  layers.Flatten(),\n",
    "  # layers.Dropout(0.2),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(class_count, activation=\"softmax\", name=f\"output\")\n",
    "])"
   ],
   "metadata": {
    "id": "DzeDPLjiivAd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "id": "S3a_aMDkyR1z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "36c4f2fa-d005-4cb1-91cf-a04398706a89"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")"
   ],
   "metadata": {
    "id": "eRUGuIk3yUCY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=f\"tmp/checkpoints\",\n",
    "#     save_weights_only=False,\n",
    "#     monitor=f\"val_acc\",\n",
    "#     mode=\"max\",\n",
    "#     save_best_only=True,\n",
    "# )\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=f\"val_acc\",\n",
    "    mode=\"max\",\n",
    ")"
   ],
   "metadata": {
    "id": "WteS3nFgyVxh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not COLAB:\n",
    "    !aws s3 cp \"s3://.../tf/tf-exam/image-classification/model.h5\" \"$tmp_path/model.h5\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights(f\"{tmp_path}/model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[reduce_lr_callback],\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lrqq-KMKyYLp",
    "outputId": "0384163e-1d32-4780-e46d-39945e362a05"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Training accuracy\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Validation accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "DgkLKpp80Kkm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "outputId": "c7fc12b0-a11d-45cd-a835-5fca61e8733a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.save(\"tmp/model.h5\", save_format=\"h5\")"
   ],
   "metadata": {
    "id": "IlzvZx-BO4a3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
