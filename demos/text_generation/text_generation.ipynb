{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "V100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install tiktoken"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvxTcZQ3ejiV",
    "outputId": "02a5fa5b-b9f0-4470-d8cc-5e5cb6cb9eae"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4G1TuXieb1w",
    "outputId": "44bb9b03-74bc-4ceb-c6ff-0d965c5abd1a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "from shutil import copyfileobj\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "from random import shuffle\n",
    "import tiktoken\n",
    "\n",
    "import zipfile\n",
    "\n",
    "print(f\"TF version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# def archive(dir: Path):\n",
    "#     with zipfile.ZipFile(f\"{dir}.zip\", \"w\", zipfile.ZIP_STORED) as zip_file:\n",
    "#         for entry in dir.rglob(\"*\"):\n",
    "#             zip_file.write(entry, entry.relative_to(dir))\n",
    "#\n",
    "#\n",
    "# def unarchive(file: Path):\n",
    "#     with zipfile.ZipFile(file, \"r\") as zip_file:\n",
    "#         zip_file.extractall(file.with_suffix(\"\"))"
   ],
   "metadata": {
    "id": "C3ZqAZ4iefFk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def download_file(url, dataset_file_path):\n",
    "    path = Path(dataset_file_path)\n",
    "    os.makedirs(path.parent, exist_ok=True)\n",
    "    if not path.exists():\n",
    "        print(f\"Downloading {path}\")\n",
    "        with urlopen(url) as fsrc, open(path, \"wb\") as fdst:\n",
    "            copyfileobj(fsrc, fdst)\n",
    "    else:\n",
    "        print(f\"File {path} exists\")"
   ],
   "metadata": {
    "id": "XeDnid4NegkC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "CftBn65vehg9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = \"tmp/text_generation.json\"\n",
    "batch_size = 1024\n",
    "seed = 123\n",
    "max_seq_length = 100"
   ],
   "metadata": {
    "id": "ozHzcSBkeqYu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "download_file(\"https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k/raw/main/code_alpaca_20k.json\", dataset_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFYaSXcFeqxP",
    "outputId": "b6b957cf-b227-4c3f-f137-0858d2dc9a1d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "json_dataset = None\n",
    "with open(dataset_path) as f:\n",
    "    # noinspection PyRedeclaration\n",
    "    json_dataset = json.load(f)"
   ],
   "metadata": {
    "id": "Sz3-7nnXesg8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "json_dataset[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12X00F81ett8",
    "outputId": "885fff39-d82a-472e-ecb8-7adce73122eb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = [f\"instruction: {item['instruction']}\\ninput: {item['input']}\\noutput: {item['output']}\"\n",
    "           for item in json_dataset]\n",
    "shuffle(dataset)"
   ],
   "metadata": {
    "id": "FS8KYaWjevEc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "sequences = [tokenizer.encode(s) for s in dataset]\n",
    "max(len(s) for s in sequences)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlp3zxGaewQN",
    "outputId": "f827a9ee-34e5-4b27-b7e3-a02a0f52b393"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_samples(lst, max_seq_length):\n",
    "    seq = lst[:max_seq_length + 1]\n",
    "    if len(lst) >= 2:\n",
    "        samples = []\n",
    "        for i in range(len(seq) - 1):\n",
    "            sequence = seq[:i + 2]\n",
    "            prefix = sequence[:-1] + ([0] * (max_seq_length + 1 - len(sequence)))\n",
    "            completion = sequence[-1]\n",
    "            samples.append((prefix, completion))\n",
    "        return samples\n",
    "    else:\n",
    "        return []"
   ],
   "metadata": {
    "id": "wsVplYXkez5d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "samples = []\n",
    "for i in range(len(sequences)):\n",
    "    samples.extend(make_samples(sequences[i], max_seq_length))\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"seq {i} out of {len(sequences)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIcCGuN1e2Wd",
    "outputId": "80d39a38-e6f1-43a1-e59c-fc35fcaf1f9c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plus OOV token and 0 index representing a mask\n",
    "input_dim = tokenizer.n_vocab + 2"
   ],
   "metadata": {
    "id": "lO26kM6We4zG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.n_vocab"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GX_AxVIRe6RV",
    "outputId": "5010e0d4-9060-496e-f9db-4524072b47ca"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "split_size = 0.9\n",
    "train_dataset = samples[:int(len(samples) * split_size)]\n",
    "validation_dataset = samples[len(train_dataset):]\n",
    "print(len(train_dataset), len(validation_dataset))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l932CYHMe7a9",
    "outputId": "1965f801-761e-4b53-f426-40e44b27e903"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_prefixes = [prefix for prefix, completion in train_dataset]\n",
    "train_completions = [completion for prefix, completion in train_dataset]\n",
    "validation_prefixes = [prefix for prefix, completion in validation_dataset]\n",
    "validation_completions = [completion for prefix, completion in validation_dataset]"
   ],
   "metadata": {
    "id": "G4-Fm8iDe8fN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_prefixes = np.array(train_prefixes)\n",
    "train_completions = np.array(train_completions)\n",
    "validation_prefixes = np.array(validation_prefixes)\n",
    "validation_completions = np.array(validation_completions)"
   ],
   "metadata": {
    "id": "0RuRve_Gg24S"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "fwwpwT0oe-TO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # text_vectorization_layer,\n",
    "\n",
    "    layers.Embedding(input_dim, 64, mask_zero=True, input_length=max_seq_length),\n",
    "    layers.LSTM(256, return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    # tf.keras.layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(tokenizer.n_vocab, activation=\"softmax\", name=f\"output\")\n",
    "])"
   ],
   "metadata": {
    "id": "umsJEI8kfAFT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHqfMIUAfAb1",
    "outputId": "b13a45a2-9715-441e-8640-fb26c0eb221f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")"
   ],
   "metadata": {
    "id": "ApI4bU5sfCOt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=f\"tmp/checkpoints\",\n",
    "#     save_weights_only=False,\n",
    "#     monitor=f\"val_acc\",\n",
    "#     mode=\"max\",\n",
    "#     save_best_only=True,\n",
    "# )\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=f\"val_acc\",\n",
    "    mode=\"max\",\n",
    ")"
   ],
   "metadata": {
    "id": "lnKX8YMHfEBl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "_pNbpa6cgzBa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 1\n",
    "history = model.fit(\n",
    "    x=train_prefixes,\n",
    "    y=train_completions,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=250,\n",
    "    callbacks=[reduce_lr_callback],\n",
    "    validation_data=(validation_prefixes, validation_completions),\n",
    "    validation_steps=20,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3-SIeI-SUWU",
    "outputId": "8f473ca9-6498-4b03-a228-7bdd25db5f8d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "2fB2H-o1om-B",
    "outputId": "fccd8bc2-ead8-4f1d-e484-46f45a7c02ab"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "-JneQa1xnoof"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def pad(tokens, max_seq_length):\n",
    "  assert len(tokens) <= max_seq_length\n",
    "  return tokens + ([0] * (max_seq_length - len(tokens)))"
   ],
   "metadata": {
    "id": "DXtHPkH7o8XI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.decode(train_prefixes[100])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Aj99leqTrSRl",
    "outputId": "aec5607f-0fbc-4d55-f924-6e315abf9853"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# input = \"instruction: Design an algorithm to print out the prime numbers between 1 and 100.\\ninput: \\noutput: \"\n",
    "input = \"instruction: Create a JavaScript to switch between two div components.\\ninput: \\noutput: \""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36C6iTuOmd1N",
    "outputId": "7977438d-d1f6-439c-fd56-0d541c049baf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_completion(input):\n",
    "  input_tokens = tokenizer.encode(input)\n",
    "  input_padded = pad(input_tokens, max_seq_length)\n",
    "  print(tokenizer.decode(input_padded))\n",
    "  completion = input_padded.copy()\n",
    "  for i in range(max_seq_length - len(input_tokens)):\n",
    "  # for i in range(100):\n",
    "    output = model(tf.expand_dims(completion, 0))[0]\n",
    "    # token = tf.argmax(output)\n",
    "    top_k = tf.math.top_k(output, k=3)\n",
    "    # print(f\"top_k: {top_k}\")\n",
    "    # print(f\"top_k tokens: {tokenizer.decode(top_k.indices)}\")\n",
    "    # p_sum = sum(top_k.values)\n",
    "    # p = top_k.values.numpy().astype(np.float32) / p_sum\n",
    "    token = np.random.choice(top_k.indices)\n",
    "    # print(f\"token: {token} '{tokenizer.decode([token])}'\")\n",
    "    completion[i + len(input_tokens)] = token\n",
    "  return tokenizer.decode(completion)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iD4iF2Yo2FO",
    "outputId": "06863da2-840c-4235-9e46-4144d85c8f71"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generate_completion(input)"
   ],
   "metadata": {
    "id": "paDBhOfqLvvD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.save(\"tmp/model.h5\", save_format=\"h5\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHklYz2Vqifm",
    "outputId": "e0d2e6f6-8baa-4d41-d522-7c5c3fac937f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "7tK7p6y3pxfQ"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
